

<p><b>ANOCHA SUTAVEEPHAMOCHANON (RUGCHATJAROEN)</b></p>

<p>Email: e1101529 (at) u.nus.edu, ranocha (at) gmail.com           Mobile: +65 84745655</p>
<p>LinkedIn: <a href="https://www.linkedin.com/in/anocha-sutaveephamochanon-rugchatjaroen-11161b38">www.linkedin.com/in/anocha-sutaveephamochanon-rugchatjaroen-11161b38</a></p>

<p>Github: <a href="https://github.com/anochasut/anochasut.github.io">https://github.com/anochasut/anochasut.github.io</a></p>
<hr>
<p><b>ABOUT ME</b></p>

<p>
I am a passionate and results-driven professional with a strong foundation in AI, machine learning, data science, and research. Over the years, I’ve gained hands-on experience in various domains, ranging from AI model development to data analysis, and have worked in diverse environments, including research institutions, academic settings, and industry-related projects. I am particularly enthusiastic about applying advanced technologies to solve real-world problems, with a focus on fostering collaboration and creating data-driven solutions.

I hold a PhD in Articulatory-based Speech Synthesis from the University of York, where I researched the simulation of human speech pressure propagation. My work was funded by the Thai Royal Government scholarship, and it provided me with a deep understanding of computational modeling and problem-solving, which has been instrumental in my subsequent projects. In addition to my PhD, I am currently advancing my knowledge through AI and machine learning courses at the National University of Singapore.

In my research role at NECTEC (National Electronics and Computer Technology Center) in Thailand, I applied my technical expertise to data analysis and AI model development, working closely with both technical and non-technical stakeholders to ensure the successful delivery of projects. My proficiency in Python, PySpark, scikit-learn, and other data science tools has enabled me to analyze complex datasets and provide actionable insights to improve processes and outcomes.
</p>
<p>
I am also deeply passionate about the evolving field of Generative AI and Natural Language Processing (NLP). I have worked on various AI-based projects, including sentiment analysis, depression detection from voice clips, and AI-powered chatbots for mental health support. My interest in AI’s transformative potential extends to creating content and enabling others to understand the implications of these technologies in everyday life, and I have contributed to the development of reports, articles, and training materials.

Beyond my technical expertise, I value continuous learning and collaboration. I believe in the power of cross-functional teamwork and strategic thinking, and I strive to contribute to initiatives that drive innovation, efficiency, and growth. With my experience in AI, data analytics, research, and content creation, I aim to continue contributing to impactful projects that harness the power of technology to shape the future.
</p>
 
<p>
Current Master of Computing postgraduate specializing in Artificial Intelligence, Natural Language Processing, and Speech Synthesis. With a solid foundation in the physics of human speech and extensive research experience in speech synthesis methodologies, I am eager to apply my knowledge and skills to contribute effectively in a professional setting. My ongoing coursework at the National University of Singapore is further enhancing my understanding of machine learning and artificial intelligence. I am actively seeking full-time positions in the Speech processing, AI and Machine Learning industry, with a targeted start date of Jan 2025.
</p>

<p><b>EDUCATION</b></p>

<ul>
<li><p>National University of Singapore                              (Jan 2022 - Present)</p>

<p>Masters of Computing - Specialization in Artificial Intelligence</p>

<p>Favorite Coursework: NLP, Text mining, Intelligent Systems and Techniques, Sound and Music Computing</p>
</li>
 

<li><p>University of York    (Jun 2010 - Nov 2014)</p>

<p>PhD in Electronic Engineering</p>

<p>Thesis title: <a href = "https://etheses.whiterose.ac.uk/7109/1/AnochaRugchatjaroen_FullThesis_Corrected.pdf">Articulatory-Based English Consonant Synthesis in 2-D Digital Waveguide Mesh</a></p>
</li>


 

<li><p>Chulalongkorn University         (May 1999 - Oct 2002)</p>

<p>Master of Science</p>

<p>Thesis title: <a href="https://cuir.car.chula.ac.th/handle/123456789/65399">Generalization of an Elliptic Radial Basis Function Neural Network</a></p>

</li>
</ul>
 

<p><b>WORK experience</b></p>
<ul>
<li><p>Senior Researcher      (Oct 2014 - Oct 2022)</p>
<p>National Electronic and Computer Technology Center, Thailand – Social Web Technology Research Team </p>
	<ul>
		<li><p>Research sub-team leader for 1.5 years</p></li>

		<li><p>Study TWG AI Standard Lanscape (2022) and AI Standardisation Landscape State of play and link to the EC proposal for an AI regulatory framework (2021) from AI Watch.M</p></li>

		<li><p>Research on Emojis usage in Thai tweets and achieve 74.49% of accuracy [16]</p></li>

		<li><p>Research on Thai mono-syllable set of words for preschoolers [15]</p></li>
	</ul>
</li>

<li><p>PhD candidate (Apr 2010 - Nov 2014)</p>

<p>Audio Lab, University of York</p>

	<ul>
		<li><p>Mark and extract MRI-data to be used as cross-sectional areas for vocal tract modeling (ITK-SNAP, ParaView)</p></li>

		<li><p>Apply Electro Magnetic Articulograph (EMA) to control articulation English consonant synthesis (Matlab) and achieve 40.28% of accuracy https://etheses.whiterose.ac.uk/7109/1/AnochaRugchatjaroen_FullThesis_Corrected.pdf</p></li>

		<li><p>Model vocal tract for consonant synthesis using Digital Wave Guide Mesh (DWM)</p></li>

		<li><p>Work on English consonants, vowels and diphthong acoustic properties</p></li>
	</ul>
</li> 

<li><p>Research Assistant  Jun 2004 – Mar 2010</p>

<p>National Electronic and Computer Technology Center, Thailand – Human Language Technology Lab</p>

	<ul>
		<li><p>Research and develop on Vaja 8 Thai Speech Synthesizer (http://vaja.nectec.or.th) achieved the best version of HMM-based Speech Synthesis for Thai language at that time.</p></li>

		<li><p>Research on Thai Grapheme to Phoneme Conversion via feature engineering achieved  9.94% WER [12, 15] <a href="https://doi.org/10.1016/j.specom.2018.12.003">https://doi.org/10.1016/j.specom.2018.12.003</a> </p></li>

		<li><p>Visited researcher on Thai Question file (Linguistic features) for HTS at Tokuda-Nankaku Laboratory, Nagoya Institute of Technology [14] achieved tone correctness at about 14.1% objectively and</p></li>

	90% subjectively <a href="https://ieeexplore.ieee.org/document/8282192">https://ieeexplore.ieee.org/document/8282192</a> 

		<li><p>Research on Thai Speech Corpus design for speaker adaptation</p></li>

		<li><p>Teach and advise how to use HTS to train tonal language speech synthesizer [6]</p></li>

	</ul> 
</li>
</ul>

<p><b>Selected projects</b></p>

<ul>
	<li><p>Recent Term Projects from Master of Computing Persuading (AI Specialization)     (Jan 2023 - Present)</p>

	<p>NUS - School of Computing </p>
	<ul>
		<li>Completed projects in Deep Learning, Uncertainty AI, and Text Mining, including weapon detection, benign/tumor detection using MRF, and r/WallStreetBets sentiment analysis</li>
		<li>Developed a simulation of urban mobility in Singapore for AI Planning and Decision-Making course</li>
		<li>Predicted Singapore HDB rental prices using knowledge discovery and data mining techniques</li>
		<li>Analyzed the impact of COVID-19 using Twitter data for Big-Data Analytics Technology project</li>
		<li>Designed an AI-based chatbot for mental health support in Human-centered Intelligence Systems course</li>
	</ul>
	</li>


	<li><p>AI Standard Landscape for Thai                           (Apr 2022 - Oct 2022)</p>

	<p>A study on TWG AI Standard</p>

	<ul>
		<li>Study TWG AI Standard Lanscape (2022) and AI Standardisation Landscape State of play and link to the EC proposal for an AI regulatory framework (2021) from AI Watch.</li>

		<li>Create a guidance for adaptation into Thai context</li>
	</ul>
	</li>
 

	<li><p>AI for Thai        ( Jul 2019 - Oct 2022)</p>

	<p>Coordinator NLP APIs – www.aiforthai.com</p>

	<ul>
		<li>Project proposal drafting</li>

		<li>Collaborate and support core NLP APIs deployment such word segmentation and question answering ones.</li>

		<li>Educate users</li>
	</ul>
	</li>
 

	<li><p>Thai Natural Language Understanding (May 2016 - Oct 2022)</p>
	<ul>
		<li>Emotion detection and tweets analysis</li>

		<li>Utilized Robotic Operating System (ROS) with computer vision algorithms to steer an autonomous vehicle through a simulated world and avoid moving obstacles 0% collision rate.</li>

		<li>Generated custom datasets and trained deep neural network models in TensorFlow Keras to identify license plates in a noisy environment and classify their characters with 90% accuracy.</li>

		<li>Returned as a Teaching Assistant in next year to oversee labs for a class of 3rd year students and provided guidance in course concepts and working within Linux terminal.</li>

	</ul>
	</li>


	<li><p>Vaja Thai Text to Speech Synthesis (V.3-V.8)         (May 2004 - Apr 2016)</p>
	<p>Thai Text to Speech Synthesis using Concatenative and HMM-based approach</p>

	<ul>
		<li>Research on Thai HTS speech synthesizer [6]</li>

		<li>The products are on Windows Platform with UI, Web-based application, API and SAPI</li>

		<li>Research and develop tools for finding concatenation cost for Thai unit selection speech synthesizer</li>

		<li>Research and develop tools for reducing speech corpus size by ADPCM encoding</li>
	</ul>
	</li>

</ul>

<p><b>TECHNICAL skills (“TECH STACK”)</b></p>


<p>Programing languages: Python, MATLAB, Java, C, HTML</p>

<p>Libraries: PyTorch, Tensorflow, Numpy, SciPy, Scikit-learn, NLTK, SpaCy PySpark, Matplotlib, Torchaudio, Speechbrain</p>

<p>Frameworks: GIT, Conda, Linux, Bash</p>

<p>Tools: Praat, Simulation of Urban MObility (SUMO)</p>

 

<p><b>Languages</b></p>

English, Thai

 

<p><b>INTERESTS & Hobbies</b></p>

Community Cat feeder/rescuer

 

<p><b>Selected publications</b></p>

<p>[1] A. Rugchatjaroen, K. Na Nakornpanom, C. Lursinsap, and S. Siripant, UGeneralizing a Generic Elliptic RBF learning by BootstrapU, 9th International Conference on Neural Information Processing, Nov 2002, Singapore. [link]</p>

<p>[2] C. Hansakunbuntheung, A. Rugchatjaroen, C. Wutiwiwatchai, USpace Reduction of Speech Corpus Based on Quality Perception for Unit Selection Speech SynthesisU, SNLP 2005, Dec 2005, Thailand. [link]</p>

<p>[3] A. Rugchatjaroen, A. Thangthai, S. Saychum, N. Thatphithakkul and C. Wutiwiwatchai, Prosody-based Naturalness Improvement in Thai Unit-selection Speech Synthesis, ECTI-CON 2007, May 2007, Thailand. (Best paper award) [link]</p>

<p>[4] S. Saychum, A. Rugchatjaroen, N. Thatphithakkul,C. Wutiwiwatchai and A. Thangthai, Automatic Duration Weighting in Thai Unit-selection Speech Synthesis, ECTI-CON 2008, May 2008, Thailand. (Best paper award) [link]</p>

<p>[5] U. Sherpa, D. Pemo, D. Chhoeden, A. Rugchatjaroen, A. Thangthai, C. Wutiwiwatchai, Pioneering Dzongkha Text-to-Speech Synthesis, O-Cocosda 2008, Nov 2008, Japan [link]</p>

<p>[6] A. Rugchatjaroen, N. Thatphithakkul, A. Chotimongkol, A. Thangthai, C. Wutiwiwatchai, Speaker adaptation using a parallel phone set pronunciation dictionary for Thai-English bilingual TTS, INTERSPEECH 2009, Sep 2009, United Kingdom. [link]</p>

<p>[7] A. Rugchatjaroen and D. Howard, A Study on Dynamic Vocal Tract Shaping for Diphthong Simulation using 2D Digital Waveguide Mesh, DAFX 2012, Sep 2012, United Kingdom. [link]</p>

<p>[8] A. Rugchatjaroen and D. M. Howard, The Acoustics of Constriction in a Vocal Tract Model using 2D Digital Waveguide Modelling, 10th International Seminar on Speech Production, May 2014, Cologne, Germany. [link]</p>

<p>[9] A. Rugchatjaroen and D. M. Howard, Flexibility Of Cosine Impedance Function In 2-D Digital Waveguide Mesh For Plosive Synthesis, in 2014 2nd IEEE China Summit & International Conference on Signal and Information Processing, July 2014, Xi' an, China. [link]</p>

<p>[10] S. Kongyoung and A. Rugchatjaroen, Thai Pseudo syllable segmentation using conditional random field, in IEEE - 2015 International Conference Oriental COCOSDA, Oct 2015, Shanghai, China</p>

<p>[11] S. Saychum, S. Kongyoung, A. Rugchatjaroen, P. Chootrakool, S. Kasuriya and C. Wuttiwiwatchai, Efficient Thai Grapheme-to-Phoneme Conversion Using CRF-Based Joint Sequence Modeling, INTERSPEECH 2016, Sep 2016, San Francisco. [link]</p>

<p>[12] A. Rugchatjaroen, D. Howard, An Evaluation of Rectilinear Digital Waveguide Mesh in Modelling Branch Tube for English Nasal Synthesis, in J of Applied Acoustics 122C (2017) pp. 1-7 [link]</p>

<p>[13] A. Rugchatjaroen, S. Saychum, K. Oura, and K. Tokuda, Generalization of Thai Tone Contour in HMM-Based Speech Synthesis, APSIPA 2017, Nov 2017, Kuala Lumpur. [link]</p>

<p>[14] A. Rugchatjaroen, S. Saychum, S. Kongyoung, P. Chootrakool, S. Kasuriya, C. Wutiwiwatchai, Efficient two-stage processing for joint sequence model-based Thai grapheme-to-phoneme conversion, in Speech Communication 106C (2019) pp. 105-111 [link]</p>

<p>[15] A. Hemakom, S. Jitwiriyanont, A. Rugchatjaroen, P. Israsena, The Development of Thai Monosyllabic Word and Picture Lists Applicable to Interactive Speech Audiometry in Preschoolers, in J of Clinical Linguistics & Phonetics, (2020) [link]</p>

<p>[16] S. Kongyoung, K. Trakultaweekoon and A. Rugchatjaroen, Thai Language Tweet Emotion based on Use of Emojis, in Proc. 16th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP 2021), Dec 21-23, 2021, online. [link]</p>

 

 
